{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### import packags\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1., -1.,  1.], grad_fn=<AddBackward0>)\n",
      "tensor([1., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "# test binary_quantization function\n",
    "def binary_quantization(x):\n",
    "    # x_back is the actual tensor for gradient computation\n",
    "    # while sign(x) is the forwarded tensor\n",
    "    # detach() can eliminate the gradient\n",
    "    x_back = torch.clamp(x, -1, 1)\n",
    "    return (torch.sign(x) - x_back).detach() + x_back\n",
    "\n",
    "\n",
    "x = torch.tensor([0.4, -0.5, 1.6]).requires_grad_()\n",
    "x_bin = binary_quantization(x)\n",
    "# print the result after binarization\n",
    "print(x_bin)\n",
    "y = x_bin.sum()\n",
    "y.backward()\n",
    "# print the gradient of x\n",
    "print(x.grad)\n",
    "\n",
    "#Feeforwarding: quantize all positive numbers in tensor to 1, and negative numbers to -1,\n",
    "#Backpropagation: results as the gradient of tensor is 1 in the range of -1 to 1, and the rest is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0879, -0.0779,  0.0986],\n",
      "          [ 0.0397,  0.1378, -0.0068],\n",
      "          [-0.1326, -0.0492, -0.0449]],\n",
      "\n",
      "         [[-0.0937, -0.0988,  0.0304],\n",
      "          [ 0.1343, -0.1387, -0.0684],\n",
      "          [-0.0911, -0.0878,  0.0209]],\n",
      "\n",
      "         [[ 0.0025,  0.0085,  0.1308],\n",
      "          [ 0.0674,  0.0226,  0.1154],\n",
      "          [-0.1293,  0.0233, -0.1071]],\n",
      "\n",
      "         [[-0.0909,  0.1374, -0.1335],\n",
      "          [ 0.0199, -0.0139, -0.1298],\n",
      "          [-0.1239,  0.0070,  0.0467]],\n",
      "\n",
      "         [[-0.0936,  0.0970,  0.0071],\n",
      "          [-0.0998, -0.0025, -0.0651],\n",
      "          [-0.1188,  0.1237,  0.1190]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0081, -0.0452,  0.1301],\n",
      "          [-0.1139, -0.0137, -0.0124],\n",
      "          [ 0.0408, -0.0659, -0.0542]],\n",
      "\n",
      "         [[ 0.0598,  0.0769, -0.0684],\n",
      "          [ 0.0200,  0.1046, -0.0009],\n",
      "          [ 0.0560,  0.1162,  0.0274]],\n",
      "\n",
      "         [[-0.1379, -0.1167,  0.0161],\n",
      "          [-0.1301,  0.0041,  0.0819],\n",
      "          [-0.0137,  0.1471, -0.0768]],\n",
      "\n",
      "         [[-0.0921, -0.0459,  0.1047],\n",
      "          [ 0.0660, -0.1000,  0.0670],\n",
      "          [ 0.0292, -0.1384, -0.1463]],\n",
      "\n",
      "         [[ 0.1186,  0.0150, -0.1150],\n",
      "          [-0.1209, -0.0889, -0.1254],\n",
      "          [ 0.0102,  0.1209, -0.1128]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0632,  0.0326, -0.0153],\n",
      "          [-0.0050,  0.1402, -0.0403],\n",
      "          [-0.1048,  0.0149, -0.1475]],\n",
      "\n",
      "         [[-0.1135, -0.1233, -0.0949],\n",
      "          [-0.0263,  0.0696,  0.1218],\n",
      "          [ 0.1432, -0.0625, -0.1467]],\n",
      "\n",
      "         [[-0.0633, -0.1268,  0.0037],\n",
      "          [-0.0306, -0.1443, -0.0369],\n",
      "          [ 0.0489,  0.0039,  0.0825]],\n",
      "\n",
      "         [[ 0.0741,  0.0586,  0.0450],\n",
      "          [-0.1168,  0.0025,  0.1196],\n",
      "          [-0.1186,  0.0122, -0.0589]],\n",
      "\n",
      "         [[ 0.1297,  0.0990,  0.0787],\n",
      "          [-0.1379, -0.1266, -0.1034],\n",
      "          [-0.1067,  0.0133,  0.0952]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0864,  0.0718, -0.1123],\n",
      "          [-0.0366, -0.1437, -0.1132],\n",
      "          [ 0.1309, -0.0138,  0.1078]],\n",
      "\n",
      "         [[-0.0747, -0.1084,  0.0545],\n",
      "          [ 0.1389, -0.0320, -0.1199],\n",
      "          [-0.1254,  0.1189, -0.0938]],\n",
      "\n",
      "         [[ 0.0380, -0.1036, -0.1237],\n",
      "          [ 0.0803, -0.0951, -0.1083],\n",
      "          [ 0.0691,  0.0585, -0.0067]],\n",
      "\n",
      "         [[-0.0010,  0.1172,  0.0168],\n",
      "          [-0.0272, -0.1271,  0.0255],\n",
      "          [-0.1143, -0.1433,  0.1181]],\n",
      "\n",
      "         [[-0.1404,  0.0778, -0.0337],\n",
      "          [-0.0446,  0.0102,  0.1308],\n",
      "          [ 0.0093, -0.0109,  0.0772]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0832,  0.0970,  0.0891],\n",
      "          [ 0.1434, -0.0720, -0.0082],\n",
      "          [ 0.0892,  0.1037,  0.0934]],\n",
      "\n",
      "         [[ 0.1288, -0.1005,  0.0793],\n",
      "          [-0.0689, -0.0736, -0.1241],\n",
      "          [ 0.0884,  0.1054,  0.0215]],\n",
      "\n",
      "         [[-0.1083,  0.0650, -0.1232],\n",
      "          [ 0.0715,  0.0981, -0.0865],\n",
      "          [ 0.0197, -0.0327, -0.1449]],\n",
      "\n",
      "         [[-0.0716, -0.0394,  0.1419],\n",
      "          [-0.0762,  0.0784,  0.1487],\n",
      "          [ 0.0837, -0.0405, -0.0617]],\n",
      "\n",
      "         [[ 0.0168, -0.0233, -0.1491],\n",
      "          [ 0.1390,  0.0606, -0.1159],\n",
      "          [ 0.0597,  0.0676, -0.0261]]],\n",
      "\n",
      "\n",
      "        [[[-0.0376, -0.0622, -0.0109],\n",
      "          [ 0.0417, -0.0093,  0.0324],\n",
      "          [ 0.0244,  0.0495,  0.0834]],\n",
      "\n",
      "         [[ 0.0653, -0.0330,  0.0534],\n",
      "          [ 0.1450,  0.0308, -0.1149],\n",
      "          [ 0.0762,  0.0665, -0.1222]],\n",
      "\n",
      "         [[-0.0720,  0.0118,  0.0575],\n",
      "          [-0.1490,  0.0677,  0.1198],\n",
      "          [ 0.0650, -0.0345, -0.0039]],\n",
      "\n",
      "         [[-0.1225, -0.0143,  0.1129],\n",
      "          [-0.1082, -0.0622,  0.1355],\n",
      "          [ 0.0787, -0.1446, -0.0976]],\n",
      "\n",
      "         [[ 0.1350, -0.0660,  0.0633],\n",
      "          [-0.0465, -0.0697, -0.0382],\n",
      "          [-0.0466,  0.0688,  0.0541]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0656,  0.0368, -0.1019],\n",
      "          [ 0.0278, -0.0027, -0.0574],\n",
      "          [ 0.0553, -0.1251,  0.0812]],\n",
      "\n",
      "         [[-0.0938,  0.1350, -0.0066],\n",
      "          [-0.0648,  0.0607,  0.0159],\n",
      "          [-0.1080, -0.1043,  0.0171]],\n",
      "\n",
      "         [[-0.0960,  0.1293,  0.1385],\n",
      "          [ 0.1445,  0.1209,  0.0154],\n",
      "          [-0.1307,  0.0951,  0.0592]],\n",
      "\n",
      "         [[-0.0888,  0.0541,  0.0867],\n",
      "          [-0.1100, -0.0360, -0.1236],\n",
      "          [ 0.1050,  0.0735,  0.0546]],\n",
      "\n",
      "         [[ 0.1263,  0.0675,  0.1393],\n",
      "          [-0.1007, -0.1268,  0.0930],\n",
      "          [ 0.0435,  0.1037,  0.0893]]],\n",
      "\n",
      "\n",
      "        [[[-0.0295, -0.0546,  0.1138],\n",
      "          [ 0.0177, -0.0883,  0.1439],\n",
      "          [-0.1373,  0.1150, -0.1155]],\n",
      "\n",
      "         [[ 0.0775,  0.0928, -0.0307],\n",
      "          [-0.0148,  0.0269,  0.0997],\n",
      "          [ 0.0843,  0.0773,  0.0916]],\n",
      "\n",
      "         [[-0.1425,  0.0889, -0.0647],\n",
      "          [-0.0632,  0.1456, -0.0462],\n",
      "          [-0.0361, -0.1340, -0.0043]],\n",
      "\n",
      "         [[-0.0449, -0.1291, -0.0540],\n",
      "          [-0.0869, -0.1469, -0.0894],\n",
      "          [-0.0646, -0.0774, -0.0388]],\n",
      "\n",
      "         [[ 0.0625,  0.1465, -0.0953],\n",
      "          [ 0.1491, -0.1060, -0.0608],\n",
      "          [ 0.1105, -0.1353,  0.1163]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1475,  0.0417, -0.0318],\n",
      "          [-0.0669, -0.1230,  0.0373],\n",
      "          [ 0.0732, -0.0425, -0.0737]],\n",
      "\n",
      "         [[ 0.0988, -0.1446, -0.0112],\n",
      "          [-0.0260,  0.0500,  0.0776],\n",
      "          [-0.0332,  0.0162,  0.0893]],\n",
      "\n",
      "         [[-0.0092,  0.1431, -0.1368],\n",
      "          [-0.1093,  0.0643, -0.0953],\n",
      "          [ 0.0934,  0.0368, -0.0179]],\n",
      "\n",
      "         [[ 0.0140, -0.1417, -0.0103],\n",
      "          [-0.0515,  0.0037,  0.1260],\n",
      "          [ 0.1265, -0.0853, -0.0162]],\n",
      "\n",
      "         [[ 0.1344,  0.0190, -0.0453],\n",
      "          [-0.0396, -0.0810,  0.0303],\n",
      "          [-0.1001, -0.1084,  0.0505]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0372,  0.1012, -0.0316],\n",
      "          [ 0.1346,  0.1383, -0.1451],\n",
      "          [ 0.1444,  0.0563,  0.1164]],\n",
      "\n",
      "         [[-0.0156, -0.0631,  0.0614],\n",
      "          [-0.0695,  0.1436, -0.1045],\n",
      "          [-0.1045,  0.0511, -0.0332]],\n",
      "\n",
      "         [[ 0.0574,  0.0687,  0.0299],\n",
      "          [-0.0505,  0.0116, -0.0672],\n",
      "          [-0.1059,  0.1306,  0.1320]],\n",
      "\n",
      "         [[ 0.0918,  0.0287, -0.0329],\n",
      "          [-0.0815, -0.1204,  0.0909],\n",
      "          [-0.0421, -0.0385,  0.1275]],\n",
      "\n",
      "         [[ 0.0140,  0.0384,  0.0926],\n",
      "          [-0.1062, -0.0877, -0.0497],\n",
      "          [ 0.0182,  0.0071, -0.0788]]]])\n",
      "tensor([[[[ 1., -1.,  1.],\n",
      "          [ 1.,  1., -1.],\n",
      "          [-1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1.,  1.],\n",
      "          [ 1., -1., -1.],\n",
      "          [-1., -1.,  1.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.],\n",
      "          [-1.,  1., -1.]],\n",
      "\n",
      "         [[-1.,  1., -1.],\n",
      "          [ 1., -1., -1.],\n",
      "          [-1.,  1.,  1.]],\n",
      "\n",
      "         [[-1.,  1.,  1.],\n",
      "          [-1., -1., -1.],\n",
      "          [-1.,  1.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1., -1.,  1.],\n",
      "          [-1., -1., -1.],\n",
      "          [ 1., -1., -1.]],\n",
      "\n",
      "         [[ 1.,  1., -1.],\n",
      "          [ 1.,  1., -1.],\n",
      "          [ 1.,  1.,  1.]],\n",
      "\n",
      "         [[-1., -1.,  1.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [-1.,  1., -1.]],\n",
      "\n",
      "         [[-1., -1.,  1.],\n",
      "          [ 1., -1.,  1.],\n",
      "          [ 1., -1., -1.]],\n",
      "\n",
      "         [[ 1.,  1., -1.],\n",
      "          [-1., -1., -1.],\n",
      "          [ 1.,  1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  1., -1.],\n",
      "          [-1.,  1., -1.],\n",
      "          [-1.,  1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [ 1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1.,  1.],\n",
      "          [-1., -1., -1.],\n",
      "          [ 1.,  1.,  1.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [-1.,  1., -1.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.],\n",
      "          [-1., -1., -1.],\n",
      "          [-1.,  1.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  1., -1.],\n",
      "          [-1., -1., -1.],\n",
      "          [ 1., -1.,  1.]],\n",
      "\n",
      "         [[-1., -1.,  1.],\n",
      "          [ 1., -1., -1.],\n",
      "          [-1.,  1., -1.]],\n",
      "\n",
      "         [[ 1., -1., -1.],\n",
      "          [ 1., -1., -1.],\n",
      "          [ 1.,  1., -1.]],\n",
      "\n",
      "         [[-1.,  1.,  1.],\n",
      "          [-1., -1.,  1.],\n",
      "          [-1., -1.,  1.]],\n",
      "\n",
      "         [[-1.,  1., -1.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [ 1., -1.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  1.,  1.],\n",
      "          [ 1., -1., -1.],\n",
      "          [ 1.,  1.,  1.]],\n",
      "\n",
      "         [[ 1., -1.,  1.],\n",
      "          [-1., -1., -1.],\n",
      "          [ 1.,  1.,  1.]],\n",
      "\n",
      "         [[-1.,  1., -1.],\n",
      "          [ 1.,  1., -1.],\n",
      "          [ 1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1.,  1.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [ 1., -1., -1.]],\n",
      "\n",
      "         [[ 1., -1., -1.],\n",
      "          [ 1.,  1., -1.],\n",
      "          [ 1.,  1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1., -1.],\n",
      "          [ 1., -1.,  1.],\n",
      "          [ 1.,  1.,  1.]],\n",
      "\n",
      "         [[ 1., -1.,  1.],\n",
      "          [ 1.,  1., -1.],\n",
      "          [ 1.,  1., -1.]],\n",
      "\n",
      "         [[-1.,  1.,  1.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [ 1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1.,  1.],\n",
      "          [-1., -1.,  1.],\n",
      "          [ 1., -1., -1.]],\n",
      "\n",
      "         [[ 1., -1.,  1.],\n",
      "          [-1., -1., -1.],\n",
      "          [-1.,  1.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  1., -1.],\n",
      "          [ 1., -1., -1.],\n",
      "          [ 1., -1.,  1.]],\n",
      "\n",
      "         [[-1.,  1., -1.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [-1., -1.,  1.]],\n",
      "\n",
      "         [[-1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.],\n",
      "          [-1.,  1.,  1.]],\n",
      "\n",
      "         [[-1.,  1.,  1.],\n",
      "          [-1., -1., -1.],\n",
      "          [ 1.,  1.,  1.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.],\n",
      "          [-1., -1.,  1.],\n",
      "          [ 1.,  1.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[-1., -1.,  1.],\n",
      "          [ 1., -1.,  1.],\n",
      "          [-1.,  1., -1.]],\n",
      "\n",
      "         [[ 1.,  1., -1.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.]],\n",
      "\n",
      "         [[-1.,  1., -1.],\n",
      "          [-1.,  1., -1.],\n",
      "          [-1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1.],\n",
      "          [-1., -1., -1.],\n",
      "          [-1., -1., -1.]],\n",
      "\n",
      "         [[ 1.,  1., -1.],\n",
      "          [ 1., -1., -1.],\n",
      "          [ 1., -1.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  1., -1.],\n",
      "          [-1., -1.,  1.],\n",
      "          [ 1., -1., -1.]],\n",
      "\n",
      "         [[ 1., -1., -1.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [-1.,  1.,  1.]],\n",
      "\n",
      "         [[-1.,  1., -1.],\n",
      "          [-1.,  1., -1.],\n",
      "          [ 1.,  1., -1.]],\n",
      "\n",
      "         [[ 1., -1., -1.],\n",
      "          [-1.,  1.,  1.],\n",
      "          [ 1., -1., -1.]],\n",
      "\n",
      "         [[ 1.,  1., -1.],\n",
      "          [-1., -1.,  1.],\n",
      "          [-1., -1.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  1., -1.],\n",
      "          [ 1.,  1., -1.],\n",
      "          [ 1.,  1.,  1.]],\n",
      "\n",
      "         [[-1., -1.,  1.],\n",
      "          [-1.,  1., -1.],\n",
      "          [-1.,  1., -1.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.],\n",
      "          [-1.,  1., -1.],\n",
      "          [-1.,  1.,  1.]],\n",
      "\n",
      "         [[ 1.,  1., -1.],\n",
      "          [-1., -1.,  1.],\n",
      "          [-1., -1.,  1.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.],\n",
      "          [-1., -1., -1.],\n",
      "          [ 1.,  1., -1.]]]])\n"
     ]
    }
   ],
   "source": [
    "# test binary convolutional function\n",
    "# define binary convolutional layer\n",
    "class BinConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n",
    "        super(BinConv2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups,\n",
    "                                        bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weight = binary_quantization(self.weight)\n",
    "        return F.conv2d(x, weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "# define a Binary convolution in input channel = 5，output channel = 10，kernelsize = 3\n",
    "binary_conv = BinConv2d(5, 10, 3, 1)\n",
    "print(binary_conv.weight.data)   # Print the value of convolution\n",
    "print(binary_quantization(binary_conv.weight.data))   # Print the binarized convolution, in weight value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3899, -0.1944,  0.3336, -0.1449, -0.0382],\n",
      "        [-0.2908, -0.4435, -0.2903,  0.1702,  0.2086],\n",
      "        [-0.1402, -0.0730, -0.3628, -0.4015,  0.0336],\n",
      "        [-0.0954,  0.0343, -0.2211,  0.1324,  0.4398],\n",
      "        [ 0.0139, -0.2486, -0.0754, -0.4298,  0.4461],\n",
      "        [-0.2202, -0.0181,  0.3538, -0.4103,  0.3067],\n",
      "        [-0.1179,  0.2920, -0.2143,  0.3434,  0.1513],\n",
      "        [ 0.4201, -0.2947, -0.3585,  0.0773, -0.3199],\n",
      "        [ 0.1575,  0.4039, -0.1190,  0.2671,  0.3864],\n",
      "        [ 0.3815, -0.2374, -0.4158, -0.2824,  0.2415]])\n",
      "tensor([[ 1., -1.,  1., -1., -1.],\n",
      "        [-1., -1., -1.,  1.,  1.],\n",
      "        [-1., -1., -1., -1.,  1.],\n",
      "        [-1.,  1., -1.,  1.,  1.],\n",
      "        [ 1., -1., -1., -1.,  1.],\n",
      "        [-1., -1.,  1., -1.,  1.],\n",
      "        [-1.,  1., -1.,  1.,  1.],\n",
      "        [ 1., -1., -1.,  1., -1.],\n",
      "        [ 1.,  1., -1.,  1.,  1.],\n",
      "        [ 1., -1., -1., -1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# test binary fully-connected function\n",
    "# define binary fully-connected layer\n",
    "class BinLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(BinLinear, self).__init__(in_features, out_features, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weight = binary_quantization(self.weight)\n",
    "        return F.linear(x, weight, self.bias)\n",
    "\n",
    "# Define a binary fully connected layer with an input channel of 5 and an output channel of 10\n",
    "binary_conv = BinLinear(5, 10)\n",
    "print(binary_conv.weight.data)   # Print the value of this fully connected weight\n",
    "print(binary_quantization(binary_conv.weight.data))   # Print the binarized weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5000, -0.5000,  2.0000])\n"
     ]
    }
   ],
   "source": [
    "# define LogAP2 function\n",
    "def LogAP2(x, eps=0.0):\n",
    "    # implement Most Significant Bit according to the paper\n",
    "    return torch.sign(x) * 2 ** (torch.round(torch.log2(x.abs() + eps)))\n",
    "\n",
    "# The purpose of this function is to convert any floating-point number x to its nearest second power 2^n，\n",
    "# That is, for any x, we find n such that the difference between the nth power of 2 and x is the smallest\n",
    "\n",
    "x = torch.tensor([0.4, -0.5, 1.6])\n",
    "print(LogAP2(x))\n",
    "\n",
    "# When x is abnormally small, this function will overflow due to Log, so we add eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.2608e-08,  1.4901e-08,  3.7253e-09,  1.2806e-08,  4.0978e-08,\n",
      "         3.2596e-08,  3.3528e-08, -1.5832e-08, -3.9290e-08, -3.6322e-08,\n",
      "        -4.6566e-09, -3.9116e-08, -7.9162e-08, -4.6566e-09, -7.1013e-09,\n",
      "        -3.1665e-08, -3.4925e-08,  3.8417e-08, -1.3970e-08, -1.0245e-08,\n",
      "         8.3819e-09, -4.5169e-08,  3.7253e-08,  1.4901e-08,  2.1420e-08,\n",
      "         3.7253e-08,  2.7940e-08,  4.2841e-08,  5.2154e-08,  1.6531e-08,\n",
      "         7.4506e-09,  3.2131e-08,  1.4901e-08,  3.7253e-08,  4.3772e-08,\n",
      "        -4.2841e-08,  7.9162e-09, -5.2154e-08, -5.1223e-08, -8.3819e-09,\n",
      "         0.0000e+00,  3.9814e-08,  3.8184e-08, -2.6659e-08,  1.9558e-08,\n",
      "         4.3306e-08, -5.4948e-08,  5.5879e-09,  1.5367e-08,  2.6077e-08,\n",
      "         2.5611e-08,  2.7008e-08,  1.1642e-08,  7.4506e-09,  4.2841e-08,\n",
      "        -1.5832e-08,  1.4901e-08, -5.4250e-08,  3.0734e-08,  3.2131e-08,\n",
      "        -4.8429e-08,  1.3039e-08, -1.4901e-08,  1.4901e-08])\n",
      "tensor([0.5909, 0.5210, 0.5549, 0.5710, 0.6090, 0.5835, 0.5685, 0.5852, 0.5612,\n",
      "        0.5811, 0.5320, 0.5912, 0.5747, 0.5720, 0.5852, 0.5598, 0.5453, 0.5353,\n",
      "        0.6081, 0.5167, 0.5715, 0.6046, 0.5120, 0.5538, 0.5700, 0.5440, 0.5959,\n",
      "        0.5585, 0.5566, 0.5928, 0.5531, 0.5377, 0.5342, 0.5868, 0.5956, 0.5552,\n",
      "        0.5273, 0.5434, 0.5519, 0.6125, 0.5523, 0.5100, 0.5213, 0.5439, 0.5589,\n",
      "        0.5393, 0.5792, 0.6018, 0.5673, 0.5623, 0.5813, 0.6136, 0.5567, 0.5915,\n",
      "        0.5817, 0.5438, 0.5592, 0.5801, 0.5665, 0.5689, 0.5604, 0.5146, 0.5456,\n",
      "        0.5743])\n",
      "tensor([0.9719, 0.9926, 0.9699, 0.9913, 0.9754, 0.9900, 0.9759, 0.9666, 0.9836,\n",
      "        0.9845, 0.9856, 0.9778, 0.9850, 0.9803, 0.9682, 0.9962, 0.9738, 1.0000,\n",
      "        0.9814, 0.9926, 0.9755, 0.9760, 0.9835, 0.9717, 0.9990, 0.9945, 0.9814,\n",
      "        0.9671, 0.9727, 0.9954, 0.9574, 0.9849, 0.9857, 0.9894, 0.9765, 0.9890,\n",
      "        0.9770, 0.9701, 0.9905, 0.9645, 0.9809, 0.9845, 0.9865, 0.9828, 0.9731,\n",
      "        0.9562, 0.9816, 0.9591, 0.9748, 0.9788, 0.9660, 0.9785, 0.9716, 0.9990,\n",
      "        0.9788, 0.9800, 0.9594, 0.9852, 0.9553, 0.9802, 0.9897, 0.9923, 0.9833,\n",
      "        0.9844])\n"
     ]
    }
   ],
   "source": [
    "class ShiftBatchNorm(nn.BatchNorm1d):\n",
    "    def __init__(self, channel, *args):\n",
    "        super(ShiftBatchNorm, self).__init__(channel, *args)\n",
    "\n",
    "    def round_pass(self, x):\n",
    "        # to make rounded tensor still have gradient\n",
    "        return (x.round() - x) + x\n",
    "\n",
    "    def LogAP2(self, x, eps=0.0):\n",
    "        # implement Most Significant Bit according to the paper\n",
    "        return torch.sign(x) * 2 ** (torch.round(torch.log2(x.abs() + eps)))\n",
    "\n",
    "    def get_var(self, x, mean, channel_dim):\n",
    "        # implement variance with LogAP2()\n",
    "        centerd_mean = x - mean.reshape(1, channel_dim)\n",
    "        variance = centerd_mean * self.LogAP2(centerd_mean, eps=0.0001)\n",
    "        return variance.mean([0])\n",
    "\n",
    "    def forward(self, input, round_var=True):\n",
    "        # determine the average factor and channel dimension\n",
    "        exponential_average_factor = self.momentum\n",
    "        channel_dim = input.shape[1]\n",
    "        # calculate running estimates if the model is in training\n",
    "        if self.training:\n",
    "            mean = input.mean([0])\n",
    "            var = self.get_var(input, mean, channel_dim)\n",
    "\n",
    "            # Update the running stats in Batch Normalization Layer\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = exponential_average_factor * mean + (\n",
    "                            1 - exponential_average_factor) * self.running_mean\n",
    "                # update running_var with unbiased var\n",
    "                self.running_var = exponential_average_factor * var + (\n",
    "                            1 - exponential_average_factor) * self.running_var\n",
    "        # In testing the model directly uses the running stats\n",
    "        else:\n",
    "            mean = self.running_mean\n",
    "            var = self.running_var\n",
    "\n",
    "        # calculate the normalization factor\n",
    "        div = 1 / (torch.sqrt(var.reshape(1, channel_dim) + self.eps))\n",
    "        if round_var:\n",
    "            div = self.LogAP2(div)\n",
    "        input = (input - mean.reshape(1, channel_dim)) * div  # normalize\n",
    "        return input\n",
    "    \n",
    "\n",
    "# Initialize the BatchNorm layer（channel=64）\n",
    "bn = ShiftBatchNorm(64)\n",
    "\n",
    "# Randomly create activation (Batchsize=1024, channel=64)\n",
    "x = torch.randn(1024, 64)\n",
    "\n",
    "# turn the average of activation to 3，variation to 9\n",
    "x = x * 3 + 3\n",
    "\n",
    "# Test the performance of BN\n",
    "y = bn(x)\n",
    "# Seperately print the results of average and var\n",
    "print(y.mean(0))\n",
    "print(y.var(0))\n",
    "# The reason why the variance of this is not 1 is that it was originally meant to be divided by 0.333, \n",
    "# but the LogAP2 function changed the number to be divided into 0.25, so the variance is not.\n",
    "# I set a parameter round_var, when it is set to False, the variance can be close to 1:\n",
    "y = bn(x, round_var=False)\n",
    "print(y.var(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyModel(\n",
      "  (conv1): BinLinear(in_features=1024, out_features=2048, bias=True)\n",
      "  (bn1): ShiftBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): BinLinear(in_features=2048, out_features=2048, bias=True)\n",
      "  (bn2): ShiftBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class TinyModel(nn.Module):\n",
    "\n",
    "    def __init__(self, binarized=True, res=32, rgb=False):\n",
    "        super().__init__()\n",
    "        # define network structures\n",
    "        # if binarized is set to True,\n",
    "        # we use binary linear layer and\n",
    "        # shift batchnorm layer.\n",
    "        mult = 3 if rgb is True else 1\n",
    "        if binarized is True:\n",
    "            self.conv1 = BinLinear(res * res * mult, 2048)\n",
    "            self.bn1 = ShiftBatchNorm(2048)\n",
    "            self.conv2 = BinLinear(2048, 2048)\n",
    "            self.bn2 = ShiftBatchNorm(2048)\n",
    "        else:\n",
    "            self.conv1 = nn.Linear(res * res * mult, 2048)\n",
    "            self.bn1 = nn.BatchNorm1d(2048)\n",
    "            self.conv2 = nn.Linear(2048, 2048)\n",
    "            self.bn2 = nn.BatchNorm1d(2048)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(2048, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Standard Conv-BN-Act block, note that the\n",
    "        # activation is not binarized for the first layer\n",
    "        # according to Section 2.6 in the paper.\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        # Binarize activation\n",
    "        x = binary_quantization(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = binary_quantization(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = TinyModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The storage of FP model is 25.296936000000002.MB\n",
      "The storage of binary model is 0.7905292500000001.MB\n"
     ]
    }
   ],
   "source": [
    "# Model Complexity：\n",
    "\n",
    "# Full Precision Model\n",
    "\n",
    "# count the number of parameter\n",
    "num_param = sum([i.numel() for i in model.parameters()])\n",
    "\n",
    "# turn number of parameter into megabyte:  \n",
    "# *Floating point number 32 bits / 8 bits per byte / 1024 bytes to kB / 1024 bytes to MB\n",
    "MBs = num_param * 32 / 8 / 1000 / 1000\n",
    "print('The storage of FP model is {}.MB'.format(MBs))\n",
    "\n",
    "# The parameter of the binary network is 1/32 of the original network, because it only takes up one bit。\n",
    "print('The storage of binary model is {}.MB'.format(MBs/32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    Training function for binary model\n",
    "    :param model: the binary model that needs to be optimized\n",
    "    :param device: usually GPU with cuda\n",
    "    :param train_loader: data loader of training dataset\n",
    "    :param optimizer: Adam optimizer\n",
    "    :param epoch: current training epoch\n",
    "    :return: trained model\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    # start training iterating\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # forward, compute loss, backward, update loop\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    \"\"\"\n",
    "    Test function for binary model\n",
    "    :param model: the binary model that needs to be tested\n",
    "    :param device: usually GPU with cuda\n",
    "    :param test_loader: data loader of testing dataset\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():  # no gradient signal during testing\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "# set the random seed for reproducibility\n",
    "seed = 1001\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "train_kwargs = {'batch_size': 128}\n",
    "test_kwargs = {'batch_size': 100}\n",
    "\n",
    "cuda_kwargs = {'num_workers': 1,\n",
    "               'pin_memory': True,\n",
    "               'shuffle': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------Preparing Dataset ----------------------\n",
    "# Dataset can be chosed from CIFAR10, MNIST, and SVHN\n",
    "Dset = 'MNIST'\n",
    "train_kwargs.update(cuda_kwargs)\n",
    "test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "if Dset == 'MNIST':\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    dataset1 = datasets.MNIST('data', train=True, download=True,\n",
    "                              transform=transform)\n",
    "    dataset2 = datasets.MNIST('data', train=False,\n",
    "                              transform=transform)\n",
    "    res = 28\n",
    "    rgb = False\n",
    "elif Dset == 'SVHN':\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    dataset = datasets.SVHN('data', download=True, transform=transform)\n",
    "    from torch.utils.data import random_split\n",
    "\n",
    "    val_size = 5000\n",
    "    random_seed = 42\n",
    "    torch.manual_seed(random_seed)\n",
    "    train_size = len(dataset) - val_size\n",
    "    dataset1, dataset2 = random_split(dataset, [train_size, val_size])\n",
    "    res = 32\n",
    "    rgb = True\n",
    "elif Dset == 'CIFAR':\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    dataset1 = datasets.CIFAR10(root='data', train=True, download=True, transform=transform)\n",
    "    dataset2 = datasets.CIFAR10(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "    res = 32\n",
    "    rgb = True\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model\n",
    "model = TinyModel(False, res, rgb)\n",
    "model.cuda()  # we use cuda default\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# training for 30 epochs\n",
    "epochs = 100\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=epochs, )\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()\n",
    "    \n",
    "    \n",
    "#for this step, if running code in macOS, might given error; but in windows might not.\n",
    "#there is special situation for CUDA used in different system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is figure part\n",
    "# import packages\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# total 3 bars (MNIST, SVHN, CIFAR10)\n",
    "N = 3\n",
    "\n",
    "# setup color names\n",
    "color1 = 'firebrick'\n",
    "color2 = 'steelblue'\n",
    "color3 = 'darkcyan'\n",
    "color4 = 'darkorange'\n",
    "\n",
    "# test accuracy obtained from `test.py`,\n",
    "# bar1 is the model been binarized, while\n",
    "# bar2 is the 32-bit floating-point model\n",
    "bar1 = [98.04, 83.02, 62.94]\n",
    "bar2 = [98.52, 86.42, 63.62]\n",
    "\n",
    "# setup figure,\n",
    "fig = plt.figure(dpi=120, figsize=[6, 5])\n",
    "plt.rc(\"xtick\", labelsize=14)  # fontsize of the tick labels\n",
    "plt.rc(\"ytick\", labelsize=14)\n",
    "# only one plot here\n",
    "ax = plt.subplot(111)\n",
    "# setup grid in y axis for better visualization\n",
    "ax.grid('on', axis='y', linestyle='-.', zorder=0)\n",
    "ind = np.arange(1, N+1)    # the x locations for the groups\n",
    "width = 0.3         # the width of the bars\n",
    "# plot histogram\n",
    "p1 = ax.bar([i-0.5*width for i in ind], bar1, width, bottom=0, zorder=3, color=color2, alpha=0.8)\n",
    "p2 = ax.bar([i+0.5*width for i in ind], bar2, width, zorder=3, color=color1, alpha=0.6)\n",
    "# remove top right axis for better results\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "\n",
    "# plt.setp(ax.get_xticklabels(), visible=False)\n",
    "ax.tick_params(axis='x', which='both', length=0)\n",
    "# setup x axis tick label\n",
    "ax.set_xticks(range(1, 4))\n",
    "ax.set_xticklabels(['MNIST', 'SVHN', 'CIFAR10'])\n",
    "ax.set_xlim(0.5, 3.8)\n",
    "ax.set_ylabel('Test Accuracy', fontsize=17)\n",
    "ax.legend((p1[0], p2[0]), ('Binary', 'Full Precision'), prop={'size': 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03c4313204174fe7928eba12cf77e7b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "05629bd0dad64f62ab5881c7debe2cfb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_cb73a772086649a6b00ea0b46489ecb4",
        "IPY_MODEL_b65984a5532542c6817bb0c3bc95b96b",
        "IPY_MODEL_e1143d8396a6432c985ceaa6f5dfd2f9"
       ],
       "layout": "IPY_MODEL_735789558f9b4af7bb6f8ff77b925f8e"
      }
     },
     "1f9f41cec55a4baba5d48a193705a61f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2449855a37854a3f91574cfff629cd72": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "244b797d4de7404ba6177a53c709dbaa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "247412ed323a4b099ed8f8b3063aef87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "28472d4e85274042a695afc9eff1dabe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_40c93b5b9dc842e38a61a00c46020f5a",
       "max": 1,
       "style": "IPY_MODEL_247412ed323a4b099ed8f8b3063aef87",
       "value": 1
      }
     },
     "2ddb9bc3543e4335a34138faacb56e07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "360398bf94c1470baa2d0d7ad42eb572": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e8ccda716e544ba282410e145c7c7e60",
       "style": "IPY_MODEL_70740e61bfc94f4d9757610f6d0d206e"
      }
     },
     "3a1b2af2191e46b99c3ed86be69590ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "40c93b5b9dc842e38a61a00c46020f5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "4189098f7dd34c589abd5e6f48741d2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "42ce8047392e43b79434d03dc457965f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "42e5b80f162a44dea803a13dc4aa7385": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "47638b12414d4e90a14a5e4275bb388a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_42e5b80f162a44dea803a13dc4aa7385",
       "style": "IPY_MODEL_9665d9240f7946aba1a49ed6a2c4903f",
       "value": " 32768/? [00:00&lt;00:00, 269051.33it/s]"
      }
     },
     "4793352ff0be40c981a0dff246a69753": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "49410b360a3340b887be33301cac6a4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "49b0a42260634a43a0571d4a7990518a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2ddb9bc3543e4335a34138faacb56e07",
       "style": "IPY_MODEL_1f9f41cec55a4baba5d48a193705a61f"
      }
     },
     "4c197d1130994fa6ad70856bf2dedfa6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_360398bf94c1470baa2d0d7ad42eb572",
        "IPY_MODEL_28472d4e85274042a695afc9eff1dabe",
        "IPY_MODEL_57b33812566d4c2d945acb936fd059b9"
       ],
       "layout": "IPY_MODEL_6ec77f03d0564a439fe5d470dffbb608"
      }
     },
     "4cb3404490564743bc18b9a29eecd494": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "57b33812566d4c2d945acb936fd059b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_af816cfbce774bcdbc89599c4d62d7e9",
       "style": "IPY_MODEL_ccab97c4ee144b4fb8fdfc48775238b0",
       "value": " 9920512/? [10:15&lt;00:00, 16130.70it/s]"
      }
     },
     "6ec77f03d0564a439fe5d470dffbb608": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "70740e61bfc94f4d9757610f6d0d206e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "735789558f9b4af7bb6f8ff77b925f8e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "78cb8049346244a8a9a73d71cf196d74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7bc77ce851c7472ca5a17eb926635786": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9096f0ad65f647c7b7869cbf5c87abbd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "9141c3fabf9f48799c6ccd10088b7a3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_4793352ff0be40c981a0dff246a69753",
       "max": 1,
       "style": "IPY_MODEL_3a1b2af2191e46b99c3ed86be69590ab",
       "value": 1
      }
     },
     "9665d9240f7946aba1a49ed6a2c4903f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9eeaadb402a5431ea53c90c19e586d99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_49b0a42260634a43a0571d4a7990518a",
        "IPY_MODEL_9141c3fabf9f48799c6ccd10088b7a3d",
        "IPY_MODEL_d5823135b8dc4fafa4e732ecae98f74d"
       ],
       "layout": "IPY_MODEL_4189098f7dd34c589abd5e6f48741d2f"
      }
     },
     "ab782aae2d0c466a855b6752e7a77e1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_9096f0ad65f647c7b7869cbf5c87abbd",
       "max": 1,
       "style": "IPY_MODEL_42ce8047392e43b79434d03dc457965f",
       "value": 1
      }
     },
     "af816cfbce774bcdbc89599c4d62d7e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b65984a5532542c6817bb0c3bc95b96b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_d2e74734203c46aa86269fdcf0fe2bcf",
       "max": 1,
       "style": "IPY_MODEL_78cb8049346244a8a9a73d71cf196d74",
       "value": 1
      }
     },
     "c4c1ea62dd604639932b26c63dbfa85f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_e2fea063ca5248e08365055d4a3171c8",
        "IPY_MODEL_ab782aae2d0c466a855b6752e7a77e1d",
        "IPY_MODEL_47638b12414d4e90a14a5e4275bb388a"
       ],
       "layout": "IPY_MODEL_4cb3404490564743bc18b9a29eecd494"
      }
     },
     "cb73a772086649a6b00ea0b46489ecb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_03c4313204174fe7928eba12cf77e7b1",
       "style": "IPY_MODEL_dcf908fb051e460392e5e9c3f9412cbb"
      }
     },
     "ccab97c4ee144b4fb8fdfc48775238b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d2e74734203c46aa86269fdcf0fe2bcf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "d5823135b8dc4fafa4e732ecae98f74d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_244b797d4de7404ba6177a53c709dbaa",
       "style": "IPY_MODEL_7bc77ce851c7472ca5a17eb926635786",
       "value": " 1654784/? [10:13&lt;00:00, 2698.57it/s]"
      }
     },
     "dcf908fb051e460392e5e9c3f9412cbb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e1143d8396a6432c985ceaa6f5dfd2f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2449855a37854a3f91574cfff629cd72",
       "style": "IPY_MODEL_49410b360a3340b887be33301cac6a4d",
       "value": " 8192/? [04:21&lt;00:00, 31.32it/s]"
      }
     },
     "e2fea063ca5248e08365055d4a3171c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e8e54d1910e74f078d349bc030f4bcb0",
       "style": "IPY_MODEL_e4f14d18b61b401abdcddd1893a6ff09"
      }
     },
     "e4f14d18b61b401abdcddd1893a6ff09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e8ccda716e544ba282410e145c7c7e60": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e8e54d1910e74f078d349bc030f4bcb0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
